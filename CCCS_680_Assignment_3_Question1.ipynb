{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelmalki/MichelMalki/blob/main/CCCS_680_Assignment_3_Question1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pyspark Setup and CSV Input\n",
        "\n",
        "The following notebook helps to setup pyspark on Colab as shows you how to read and extract contents from a CSV file.\n",
        "\n",
        "First we download and install Java, Spark and findspark"
      ],
      "metadata": {
        "id": "vizXrrZLSAk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"CCCS 680 Assignment 3 Question 1 \") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "5EzVOJRKSODe",
        "outputId": "e79eb9c0-78d1-4832-ef26-eef0446a2ec8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,550 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,104 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,204 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,771 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,129 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,378 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,420 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,858 kB]\n",
            "Fetched 23.7 MB in 7s (3,445 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "49 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=460df7140a6a7d10dea780b420ef6e0da22cf4799c0a273698160b339773eddf\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b322404b070>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4c9876f9635f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>CCCS 680 Assignment 3 Question 1 </code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we map our google drive. Note that you will be prompted for your google account credentials and be provided with an authorization code to insert. The contents of your google drive storage will be mounted at `/content/drive`."
      ],
      "metadata": {
        "id": "mjMfegM1Su-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABiQiXcXSzs3",
        "outputId": "bc6e1044-056a-47c6-d2be-962b1bfb3359"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchases_df = spark.read.csv('/content/drive/My Drive/CCCS-680 Assignment 3/purchases.txt.gz', inferSchema=True, header=False, sep='\\t')"
      ],
      "metadata": {
        "id": "i1EW3_ZqTP6r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purchases_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxY5xk0aVa0e",
        "outputId": "04607a66-5167-4cf6-fd52-8ff003f09e3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+--------------+--------------------+------+----------+\n",
            "|       _c0|                _c1|           _c2|                 _c3|   _c4|       _c5|\n",
            "+----------+-------------------+--------------+--------------------+------+----------+\n",
            "|2012-01-01|2024-07-25 09:00:00|      San Jose|      Men's Clothing|214.05|      Amex|\n",
            "|2012-01-01|2024-07-25 09:00:00|    Fort Worth|    Women's Clothing|153.57|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|     San Diego|               Music| 66.08|      Cash|\n",
            "|2012-01-01|2024-07-25 09:00:00|    Pittsburgh|        Pet Supplies|493.51|  Discover|\n",
            "|2012-01-01|2024-07-25 09:00:00|         Omaha| Children's Clothing|235.63|MasterCard|\n",
            "|2012-01-01|2024-07-25 09:00:00|      Stockton|      Men's Clothing|247.18|MasterCard|\n",
            "|2012-01-01|2024-07-25 09:00:00|        Austin|             Cameras| 379.6|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|      New York|Consumer Electronics| 296.8|      Cash|\n",
            "|2012-01-01|2024-07-25 09:00:00|Corpus Christi|                Toys| 25.38|  Discover|\n",
            "|2012-01-01|2024-07-25 09:00:00|    Fort Worth|                Toys|213.88|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|     Las Vegas|         Video Games| 53.26|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|        Newark|         Video Games| 39.75|      Cash|\n",
            "|2012-01-01|2024-07-25 09:00:00|        Austin|             Cameras|469.63|MasterCard|\n",
            "|2012-01-01|2024-07-25 09:00:00|    Greensboro|                DVDs|290.82|MasterCard|\n",
            "|2012-01-01|2024-07-25 09:00:00| San Francisco|               Music|260.65|  Discover|\n",
            "|2012-01-01|2024-07-25 09:00:00|       Lincoln|              Garden| 136.9|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|       Buffalo|    Women's Clothing|483.82|      Visa|\n",
            "|2012-01-01|2024-07-25 09:00:00|      San Jose|    Women's Clothing|215.82|      Cash|\n",
            "|2012-01-01|2024-07-25 09:00:00|        Boston|             Cameras|418.94|      Amex|\n",
            "|2012-01-01|2024-07-25 09:00:00|       Houston|                Baby|309.16|      Visa|\n",
            "+----------+-------------------+--------------+--------------------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.A\n",
        "\n",
        "What was the total amount sold"
      ],
      "metadata": {
        "id": "DrU2GnV1Wbfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchases_df.select(F.sum(purchases_df._c4)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHoi_-_XV7Ua",
        "outputId": "4202eb73-3777-4abc-dd4a-0bdfaa726dde"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            sum(_c4)|\n",
            "+--------------------+\n",
            "|1.0344579532600112E9|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.B\n",
        "What is the total number of transactions per store location?\n"
      ],
      "metadata": {
        "id": "74g8_yUhWvgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = purchases_df.groupBy(purchases_df._c2).count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXWH3vFaWuzn",
        "outputId": "5f9aae62-79c3-41e6-f207-e09436f09ff8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|            _c2|count|\n",
            "+---------------+-----+\n",
            "|North Las Vegas|40013|\n",
            "|        Phoenix|40333|\n",
            "|          Omaha|40209|\n",
            "|      Anchorage|39806|\n",
            "|        Anaheim|40086|\n",
            "|     Greensboro|40232|\n",
            "|         Dallas|40368|\n",
            "|        Oakland|39728|\n",
            "|         Laredo|40342|\n",
            "|     Scottsdale|40173|\n",
            "|    San Antonio|40197|\n",
            "|    Bakersfield|40326|\n",
            "|        Raleigh|40261|\n",
            "|    Chula Vista|40080|\n",
            "|   Philadelphia|40748|\n",
            "|     Louisville|40099|\n",
            "|    Los Angeles|40254|\n",
            "|       Chandler|39826|\n",
            "|     Sacramento|40561|\n",
            "|   Indianapolis|40321|\n",
            "+---------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.C\n",
        "\n",
        "What is the total sold for every combination of product type and store location\n"
      ],
      "metadata": {
        "id": "iFvOac43xMAu"
      }
    },
    {
      "source": [
        "result = purchases_df.groupBy(\"_c3\", \"_c2\").agg(F.sum(\"_c4\").alias(\"total_sold\"))\n",
        "result.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZH8NNs_XA-5",
        "outputId": "d20f01c0-d461-4016-cfa5-06461817fdcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------+-----------------+\n",
            "|                _c3|         _c2|       total_sold|\n",
            "+-------------------+------------+-----------------+\n",
            "|  Health and Beauty|   Charlotte|547280.5699999997|\n",
            "|             Crafts|      Durham|553803.5200000005|\n",
            "|   Women's Clothing|        Mesa|572868.2699999996|\n",
            "|            Cameras|       Plano|548115.3300000005|\n",
            "|Children's Clothing| Los Angeles|574671.8499999995|\n",
            "|       Pet Supplies|  Fort Wayne|560785.3400000004|\n",
            "|                CDs|Indianapolis|572676.8100000003|\n",
            "|     Men's Clothing| Baton Rouge|563814.1699999993|\n",
            "|   Women's Clothing|      Aurora|551525.0699999997|\n",
            "|  Health and Beauty|      Aurora|552101.0300000011|\n",
            "|     Sporting Goods|     Fremont| 544994.409999999|\n",
            "|             Crafts| Albuquerque|543748.6199999994|\n",
            "|            Cameras| Bakersfield|547924.4799999984|\n",
            "|            Cameras|     El Paso|        581664.08|\n",
            "|          Computers|Indianapolis|560813.3699999992|\n",
            "|                CDs|     Lubbock|521722.7599999999|\n",
            "|        Video Games|      Durham|563656.4600000015|\n",
            "|             Garden|      Austin|582794.6499999998|\n",
            "|       Pet Supplies|Jacksonville|539193.8699999994|\n",
            "|  Health and Beauty|     Garland|552989.7900000009|\n",
            "+-------------------+------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.D\n",
        "What is the maximum amount paid at each separate store location"
      ],
      "metadata": {
        "id": "ZzrhRjX-xZ9E"
      }
    },
    {
      "source": [
        "# I do find maximum amount paid in two different ways\n",
        "result = purchases_df.groupBy(\"_c2\").agg(F.max(\"_c4\").alias(\"max_amount\"))\n",
        "result.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CbjwppZxvaEq",
        "outputId": "f1be1868-55d3-4b35-f2c2-61bfb1649124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+\n",
            "|            _c2|max_amount|\n",
            "+---------------+----------+\n",
            "|North Las Vegas|    499.98|\n",
            "|        Phoenix|    499.99|\n",
            "|          Omaha|    499.99|\n",
            "|      Anchorage|    499.99|\n",
            "|        Anaheim|    499.98|\n",
            "|     Greensboro|    499.99|\n",
            "|         Dallas|    499.99|\n",
            "|        Oakland|    499.99|\n",
            "|         Laredo|    499.96|\n",
            "|     Scottsdale|    499.98|\n",
            "|    San Antonio|    499.98|\n",
            "|    Bakersfield|    499.97|\n",
            "|        Raleigh|    499.99|\n",
            "|    Chula Vista|    499.99|\n",
            "|   Philadelphia|    499.98|\n",
            "|     Louisville|    499.98|\n",
            "|    Los Angeles|    499.99|\n",
            "|       Chandler|    499.98|\n",
            "|     Sacramento|    499.96|\n",
            "|   Indianapolis|    499.98|\n",
            "+---------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = purchases_df.groupBy(purchases_df._c2).max().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2oV9wOqUkeE",
        "outputId": "e9f223fb-fd9b-478b-e961-eee0eac5b632"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------+\n",
            "|            _c2|max(_c4)|\n",
            "+---------------+--------+\n",
            "|North Las Vegas|  499.98|\n",
            "|        Phoenix|  499.99|\n",
            "|          Omaha|  499.99|\n",
            "|      Anchorage|  499.99|\n",
            "|        Anaheim|  499.98|\n",
            "|     Greensboro|  499.99|\n",
            "|         Dallas|  499.99|\n",
            "|        Oakland|  499.99|\n",
            "|         Laredo|  499.96|\n",
            "|     Scottsdale|  499.98|\n",
            "|    San Antonio|  499.98|\n",
            "|    Bakersfield|  499.97|\n",
            "|        Raleigh|  499.99|\n",
            "|    Chula Vista|  499.99|\n",
            "|   Philadelphia|  499.98|\n",
            "|     Louisville|  499.98|\n",
            "|    Los Angeles|  499.99|\n",
            "|       Chandler|  499.98|\n",
            "|     Sacramento|  499.96|\n",
            "|   Indianapolis|  499.98|\n",
            "+---------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}